// generated by stacks/gong/go/models/orm_file_per_struct_back_repo.go
package orm

import (
	"database/sql"
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"sort"
	"time"

	"gorm.io/gorm"

	"github.com/tealeg/xlsx/v3"

	"github.com/fullstack-lang/gongxsd/test/books/go/models"
)

// dummy variable to have the import declaration wihthout compile failure (even if no code needing this import is generated)
var dummy_BookType_sql sql.NullBool
var dummy_BookType_time time.Duration
var dummy_BookType_sort sort.Float64Slice

// BookTypeAPI is the input in POST API
//
// for POST, API, one needs the fields of the model as well as the fields
// from associations ("Has One" and "Has Many") that are generated to
// fullfill the ORM requirements for associations
//
// swagger:model booktypeAPI
type BookTypeAPI struct {
	gorm.Model

	models.BookType_WOP

	// encoding of pointers
	// for API, it cannot be embedded
	BookTypePointersEncoding BookTypePointersEncoding
}

// BookTypePointersEncoding encodes pointers to Struct and
// reverse pointers of slice of poitners to Struct
type BookTypePointersEncoding struct {
	// insertion for pointer fields encoding declaration

	// field Credit is a slice of pointers to another Struct (optional or 0..1)
	Credit IntSlice `gorm:"type:TEXT"`
}

// BookTypeDB describes a booktype in the database
//
// It incorporates the GORM ID, basic fields from the model (because they can be serialized),
// the encoded version of pointers
//
// swagger:model booktypeDB
type BookTypeDB struct {
	gorm.Model

	// insertion for basic fields declaration

	// Declation for basic field booktypeDB.Name
	Name_Data sql.NullString

	// Declation for basic field booktypeDB.Edition
	Edition_Data sql.NullString

	// Declation for basic field booktypeDB.Isbn
	Isbn_Data sql.NullString

	// Declation for basic field booktypeDB.Bestseller
	// provide the sql storage for the boolan
	Bestseller_Data sql.NullBool

	// Declation for basic field booktypeDB.Title
	Title_Data sql.NullString

	// Declation for basic field booktypeDB.Author
	Author_Data sql.NullString

	// Declation for basic field booktypeDB.Year
	Year_Data sql.NullInt64

	// Declation for basic field booktypeDB.Format
	Format_Data sql.NullString
	
	// encoding of pointers
	// for GORM serialization, it is necessary to embed to Pointer Encoding declaration
	BookTypePointersEncoding
}

// BookTypeDBs arrays booktypeDBs
// swagger:response booktypeDBsResponse
type BookTypeDBs []BookTypeDB

// BookTypeDBResponse provides response
// swagger:response booktypeDBResponse
type BookTypeDBResponse struct {
	BookTypeDB
}

// BookTypeWOP is a BookType without pointers (WOP is an acronym for "Without Pointers")
// it holds the same basic fields but pointers are encoded into uint
type BookTypeWOP struct {
	ID int `xlsx:"0"`

	// insertion for WOP basic fields

	Name string `xlsx:"1"`

	Edition string `xlsx:"2"`

	Isbn string `xlsx:"3"`

	Bestseller bool `xlsx:"4"`

	Title string `xlsx:"5"`

	Author string `xlsx:"6"`

	Year int `xlsx:"7"`

	Format string `xlsx:"8"`
	// insertion for WOP pointer fields
}

var BookType_Fields = []string{
	// insertion for WOP basic fields
	"ID",
	"Name",
	"Edition",
	"Isbn",
	"Bestseller",
	"Title",
	"Author",
	"Year",
	"Format",
}

type BackRepoBookTypeStruct struct {
	// stores BookTypeDB according to their gorm ID
	Map_BookTypeDBID_BookTypeDB map[uint]*BookTypeDB

	// stores BookTypeDB ID according to BookType address
	Map_BookTypePtr_BookTypeDBID map[*models.BookType]uint

	// stores BookType according to their gorm ID
	Map_BookTypeDBID_BookTypePtr map[uint]*models.BookType

	db *gorm.DB

	stage *models.StageStruct
}

func (backRepoBookType *BackRepoBookTypeStruct) GetStage() (stage *models.StageStruct) {
	stage = backRepoBookType.stage
	return
}

func (backRepoBookType *BackRepoBookTypeStruct) GetDB() *gorm.DB {
	return backRepoBookType.db
}

// GetBookTypeDBFromBookTypePtr is a handy function to access the back repo instance from the stage instance
func (backRepoBookType *BackRepoBookTypeStruct) GetBookTypeDBFromBookTypePtr(booktype *models.BookType) (booktypeDB *BookTypeDB) {
	id := backRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype]
	booktypeDB = backRepoBookType.Map_BookTypeDBID_BookTypeDB[id]
	return
}

// BackRepoBookType.CommitPhaseOne commits all staged instances of BookType to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoBookType *BackRepoBookTypeStruct) CommitPhaseOne(stage *models.StageStruct) (Error error) {

	for booktype := range stage.BookTypes {
		backRepoBookType.CommitPhaseOneInstance(booktype)
	}

	// parse all backRepo instance and checks wether some instance have been unstaged
	// in this case, remove them from the back repo
	for id, booktype := range backRepoBookType.Map_BookTypeDBID_BookTypePtr {
		if _, ok := stage.BookTypes[booktype]; !ok {
			backRepoBookType.CommitDeleteInstance(id)
		}
	}

	return
}

// BackRepoBookType.CommitDeleteInstance commits deletion of BookType to the BackRepo
func (backRepoBookType *BackRepoBookTypeStruct) CommitDeleteInstance(id uint) (Error error) {

	booktype := backRepoBookType.Map_BookTypeDBID_BookTypePtr[id]

	// booktype is not staged anymore, remove booktypeDB
	booktypeDB := backRepoBookType.Map_BookTypeDBID_BookTypeDB[id]
	query := backRepoBookType.db.Unscoped().Delete(&booktypeDB)
	if query.Error != nil {
		log.Fatal(query.Error)
	}

	// update stores
	delete(backRepoBookType.Map_BookTypePtr_BookTypeDBID, booktype)
	delete(backRepoBookType.Map_BookTypeDBID_BookTypePtr, id)
	delete(backRepoBookType.Map_BookTypeDBID_BookTypeDB, id)

	return
}

// BackRepoBookType.CommitPhaseOneInstance commits booktype staged instances of BookType to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoBookType *BackRepoBookTypeStruct) CommitPhaseOneInstance(booktype *models.BookType) (Error error) {

	// check if the booktype is not commited yet
	if _, ok := backRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype]; ok {
		return
	}

	// initiate booktype
	var booktypeDB BookTypeDB
	booktypeDB.CopyBasicFieldsFromBookType(booktype)

	query := backRepoBookType.db.Create(&booktypeDB)
	if query.Error != nil {
		log.Fatal(query.Error)
	}

	// update stores
	backRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype] = booktypeDB.ID
	backRepoBookType.Map_BookTypeDBID_BookTypePtr[booktypeDB.ID] = booktype
	backRepoBookType.Map_BookTypeDBID_BookTypeDB[booktypeDB.ID] = &booktypeDB

	return
}

// BackRepoBookType.CommitPhaseTwo commits all staged instances of BookType to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoBookType *BackRepoBookTypeStruct) CommitPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	for idx, booktype := range backRepoBookType.Map_BookTypeDBID_BookTypePtr {
		backRepoBookType.CommitPhaseTwoInstance(backRepo, idx, booktype)
	}

	return
}

// BackRepoBookType.CommitPhaseTwoInstance commits {{structname }} of models.BookType to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoBookType *BackRepoBookTypeStruct) CommitPhaseTwoInstance(backRepo *BackRepoStruct, idx uint, booktype *models.BookType) (Error error) {

	// fetch matching booktypeDB
	if booktypeDB, ok := backRepoBookType.Map_BookTypeDBID_BookTypeDB[idx]; ok {

		booktypeDB.CopyBasicFieldsFromBookType(booktype)

		// insertion point for translating pointers encodings into actual pointers
		// 1. reset
		booktypeDB.BookTypePointersEncoding.Credit = make([]int, 0)
		// 2. encode
		for _, creditAssocEnd := range booktype.Credit {
			creditAssocEnd_DB :=
				backRepo.BackRepoCredit.GetCreditDBFromCreditPtr(creditAssocEnd)
			
			// the stage might be inconsistant, meaning that the creditAssocEnd_DB might
			// be missing from the stage. In this case, the commit operation is robust
			// An alternative would be to crash here to reveal the missing element.
			if creditAssocEnd_DB == nil {
				continue
			}
			
			booktypeDB.BookTypePointersEncoding.Credit =
				append(booktypeDB.BookTypePointersEncoding.Credit, int(creditAssocEnd_DB.ID))
		}

		query := backRepoBookType.db.Save(&booktypeDB)
		if query.Error != nil {
			log.Fatalln(query.Error)
		}

	} else {
		err := errors.New(
			fmt.Sprintf("Unkown BookType intance %s", booktype.Name))
		return err
	}

	return
}

// BackRepoBookType.CheckoutPhaseOne Checkouts all BackRepo instances to the Stage
//
// Phase One will result in having instances on the stage aligned with the back repo
// pointers are not initialized yet (this is for phase two)
func (backRepoBookType *BackRepoBookTypeStruct) CheckoutPhaseOne() (Error error) {

	booktypeDBArray := make([]BookTypeDB, 0)
	query := backRepoBookType.db.Find(&booktypeDBArray)
	if query.Error != nil {
		return query.Error
	}

	// list of instances to be removed
	// start from the initial map on the stage and remove instances that have been checked out
	booktypeInstancesToBeRemovedFromTheStage := make(map[*models.BookType]any)
	for key, value := range backRepoBookType.stage.BookTypes {
		booktypeInstancesToBeRemovedFromTheStage[key] = value
	}

	// copy orm objects to the the map
	for _, booktypeDB := range booktypeDBArray {
		backRepoBookType.CheckoutPhaseOneInstance(&booktypeDB)

		// do not remove this instance from the stage, therefore
		// remove instance from the list of instances to be be removed from the stage
		booktype, ok := backRepoBookType.Map_BookTypeDBID_BookTypePtr[booktypeDB.ID]
		if ok {
			delete(booktypeInstancesToBeRemovedFromTheStage, booktype)
		}
	}

	// remove from stage and back repo's 3 maps all booktypes that are not in the checkout
	for booktype := range booktypeInstancesToBeRemovedFromTheStage {
		booktype.Unstage(backRepoBookType.GetStage())

		// remove instance from the back repo 3 maps
		booktypeID := backRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype]
		delete(backRepoBookType.Map_BookTypePtr_BookTypeDBID, booktype)
		delete(backRepoBookType.Map_BookTypeDBID_BookTypeDB, booktypeID)
		delete(backRepoBookType.Map_BookTypeDBID_BookTypePtr, booktypeID)
	}

	return
}

// CheckoutPhaseOneInstance takes a booktypeDB that has been found in the DB, updates the backRepo and stages the
// models version of the booktypeDB
func (backRepoBookType *BackRepoBookTypeStruct) CheckoutPhaseOneInstance(booktypeDB *BookTypeDB) (Error error) {

	booktype, ok := backRepoBookType.Map_BookTypeDBID_BookTypePtr[booktypeDB.ID]
	if !ok {
		booktype = new(models.BookType)

		backRepoBookType.Map_BookTypeDBID_BookTypePtr[booktypeDB.ID] = booktype
		backRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype] = booktypeDB.ID

		// append model store with the new element
		booktype.Name = booktypeDB.Name_Data.String
		booktype.Stage(backRepoBookType.GetStage())
	}
	booktypeDB.CopyBasicFieldsToBookType(booktype)

	// in some cases, the instance might have been unstaged. It is necessary to stage it again
	booktype.Stage(backRepoBookType.GetStage())

	// preserve pointer to booktypeDB. Otherwise, pointer will is recycled and the map of pointers
	// Map_BookTypeDBID_BookTypeDB)[booktypeDB hold variable pointers
	booktypeDB_Data := *booktypeDB
	preservedPtrToBookType := &booktypeDB_Data
	backRepoBookType.Map_BookTypeDBID_BookTypeDB[booktypeDB.ID] = preservedPtrToBookType

	return
}

// BackRepoBookType.CheckoutPhaseTwo Checkouts all staged instances of BookType to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoBookType *BackRepoBookTypeStruct) CheckoutPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	// parse all DB instance and update all pointer fields of the translated models instance
	for _, booktypeDB := range backRepoBookType.Map_BookTypeDBID_BookTypeDB {
		backRepoBookType.CheckoutPhaseTwoInstance(backRepo, booktypeDB)
	}
	return
}

// BackRepoBookType.CheckoutPhaseTwoInstance Checkouts staged instances of BookType to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoBookType *BackRepoBookTypeStruct) CheckoutPhaseTwoInstance(backRepo *BackRepoStruct, booktypeDB *BookTypeDB) (Error error) {

	booktype := backRepoBookType.Map_BookTypeDBID_BookTypePtr[booktypeDB.ID]

	booktypeDB.DecodePointers(backRepo, booktype)

	return
}

func (booktypeDB *BookTypeDB) DecodePointers(backRepo *BackRepoStruct, booktype *models.BookType) {

	// insertion point for checkout of pointer encoding
	// This loop redeem booktype.Credit in the stage from the encode in the back repo
	// It parses all CreditDB in the back repo and if the reverse pointer encoding matches the back repo ID
	// it appends the stage instance
	// 1. reset the slice
	booktype.Credit = booktype.Credit[:0]
	for _, _Creditid := range booktypeDB.BookTypePointersEncoding.Credit {
		booktype.Credit = append(booktype.Credit, backRepo.BackRepoCredit.Map_CreditDBID_CreditPtr[uint(_Creditid)])
	}

	return
}

// CommitBookType allows commit of a single booktype (if already staged)
func (backRepo *BackRepoStruct) CommitBookType(booktype *models.BookType) {
	backRepo.BackRepoBookType.CommitPhaseOneInstance(booktype)
	if id, ok := backRepo.BackRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype]; ok {
		backRepo.BackRepoBookType.CommitPhaseTwoInstance(backRepo, id, booktype)
	}
	backRepo.CommitFromBackNb = backRepo.CommitFromBackNb + 1
}

// CommitBookType allows checkout of a single booktype (if already staged and with a BackRepo id)
func (backRepo *BackRepoStruct) CheckoutBookType(booktype *models.BookType) {
	// check if the booktype is staged
	if _, ok := backRepo.BackRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype]; ok {

		if id, ok := backRepo.BackRepoBookType.Map_BookTypePtr_BookTypeDBID[booktype]; ok {
			var booktypeDB BookTypeDB
			booktypeDB.ID = id

			if err := backRepo.BackRepoBookType.db.First(&booktypeDB, id).Error; err != nil {
				log.Fatalln("CheckoutBookType : Problem with getting object with id:", id)
			}
			backRepo.BackRepoBookType.CheckoutPhaseOneInstance(&booktypeDB)
			backRepo.BackRepoBookType.CheckoutPhaseTwoInstance(backRepo, &booktypeDB)
		}
	}
}

// CopyBasicFieldsFromBookType
func (booktypeDB *BookTypeDB) CopyBasicFieldsFromBookType(booktype *models.BookType) {
	// insertion point for fields commit

	booktypeDB.Name_Data.String = booktype.Name
	booktypeDB.Name_Data.Valid = true

	booktypeDB.Edition_Data.String = booktype.Edition
	booktypeDB.Edition_Data.Valid = true

	booktypeDB.Isbn_Data.String = booktype.Isbn
	booktypeDB.Isbn_Data.Valid = true

	booktypeDB.Bestseller_Data.Bool = booktype.Bestseller
	booktypeDB.Bestseller_Data.Valid = true

	booktypeDB.Title_Data.String = booktype.Title
	booktypeDB.Title_Data.Valid = true

	booktypeDB.Author_Data.String = booktype.Author
	booktypeDB.Author_Data.Valid = true

	booktypeDB.Year_Data.Int64 = int64(booktype.Year)
	booktypeDB.Year_Data.Valid = true

	booktypeDB.Format_Data.String = booktype.Format
	booktypeDB.Format_Data.Valid = true
}

// CopyBasicFieldsFromBookType_WOP
func (booktypeDB *BookTypeDB) CopyBasicFieldsFromBookType_WOP(booktype *models.BookType_WOP) {
	// insertion point for fields commit

	booktypeDB.Name_Data.String = booktype.Name
	booktypeDB.Name_Data.Valid = true

	booktypeDB.Edition_Data.String = booktype.Edition
	booktypeDB.Edition_Data.Valid = true

	booktypeDB.Isbn_Data.String = booktype.Isbn
	booktypeDB.Isbn_Data.Valid = true

	booktypeDB.Bestseller_Data.Bool = booktype.Bestseller
	booktypeDB.Bestseller_Data.Valid = true

	booktypeDB.Title_Data.String = booktype.Title
	booktypeDB.Title_Data.Valid = true

	booktypeDB.Author_Data.String = booktype.Author
	booktypeDB.Author_Data.Valid = true

	booktypeDB.Year_Data.Int64 = int64(booktype.Year)
	booktypeDB.Year_Data.Valid = true

	booktypeDB.Format_Data.String = booktype.Format
	booktypeDB.Format_Data.Valid = true
}

// CopyBasicFieldsFromBookTypeWOP
func (booktypeDB *BookTypeDB) CopyBasicFieldsFromBookTypeWOP(booktype *BookTypeWOP) {
	// insertion point for fields commit

	booktypeDB.Name_Data.String = booktype.Name
	booktypeDB.Name_Data.Valid = true

	booktypeDB.Edition_Data.String = booktype.Edition
	booktypeDB.Edition_Data.Valid = true

	booktypeDB.Isbn_Data.String = booktype.Isbn
	booktypeDB.Isbn_Data.Valid = true

	booktypeDB.Bestseller_Data.Bool = booktype.Bestseller
	booktypeDB.Bestseller_Data.Valid = true

	booktypeDB.Title_Data.String = booktype.Title
	booktypeDB.Title_Data.Valid = true

	booktypeDB.Author_Data.String = booktype.Author
	booktypeDB.Author_Data.Valid = true

	booktypeDB.Year_Data.Int64 = int64(booktype.Year)
	booktypeDB.Year_Data.Valid = true

	booktypeDB.Format_Data.String = booktype.Format
	booktypeDB.Format_Data.Valid = true
}

// CopyBasicFieldsToBookType
func (booktypeDB *BookTypeDB) CopyBasicFieldsToBookType(booktype *models.BookType) {
	// insertion point for checkout of basic fields (back repo to stage)
	booktype.Name = booktypeDB.Name_Data.String
	booktype.Edition = booktypeDB.Edition_Data.String
	booktype.Isbn = booktypeDB.Isbn_Data.String
	booktype.Bestseller = booktypeDB.Bestseller_Data.Bool
	booktype.Title = booktypeDB.Title_Data.String
	booktype.Author = booktypeDB.Author_Data.String
	booktype.Year = int(booktypeDB.Year_Data.Int64)
	booktype.Format = booktypeDB.Format_Data.String
}

// CopyBasicFieldsToBookType_WOP
func (booktypeDB *BookTypeDB) CopyBasicFieldsToBookType_WOP(booktype *models.BookType_WOP) {
	// insertion point for checkout of basic fields (back repo to stage)
	booktype.Name = booktypeDB.Name_Data.String
	booktype.Edition = booktypeDB.Edition_Data.String
	booktype.Isbn = booktypeDB.Isbn_Data.String
	booktype.Bestseller = booktypeDB.Bestseller_Data.Bool
	booktype.Title = booktypeDB.Title_Data.String
	booktype.Author = booktypeDB.Author_Data.String
	booktype.Year = int(booktypeDB.Year_Data.Int64)
	booktype.Format = booktypeDB.Format_Data.String
}

// CopyBasicFieldsToBookTypeWOP
func (booktypeDB *BookTypeDB) CopyBasicFieldsToBookTypeWOP(booktype *BookTypeWOP) {
	booktype.ID = int(booktypeDB.ID)
	// insertion point for checkout of basic fields (back repo to stage)
	booktype.Name = booktypeDB.Name_Data.String
	booktype.Edition = booktypeDB.Edition_Data.String
	booktype.Isbn = booktypeDB.Isbn_Data.String
	booktype.Bestseller = booktypeDB.Bestseller_Data.Bool
	booktype.Title = booktypeDB.Title_Data.String
	booktype.Author = booktypeDB.Author_Data.String
	booktype.Year = int(booktypeDB.Year_Data.Int64)
	booktype.Format = booktypeDB.Format_Data.String
}

// Backup generates a json file from a slice of all BookTypeDB instances in the backrepo
func (backRepoBookType *BackRepoBookTypeStruct) Backup(dirPath string) {

	filename := filepath.Join(dirPath, "BookTypeDB.json")

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*BookTypeDB, 0)
	for _, booktypeDB := range backRepoBookType.Map_BookTypeDBID_BookTypeDB {
		forBackup = append(forBackup, booktypeDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	file, err := json.MarshalIndent(forBackup, "", " ")

	if err != nil {
		log.Fatal("Cannot json BookType ", filename, " ", err.Error())
	}

	err = ioutil.WriteFile(filename, file, 0644)
	if err != nil {
		log.Fatal("Cannot write the json BookType file", err.Error())
	}
}

// Backup generates a json file from a slice of all BookTypeDB instances in the backrepo
func (backRepoBookType *BackRepoBookTypeStruct) BackupXL(file *xlsx.File) {

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*BookTypeDB, 0)
	for _, booktypeDB := range backRepoBookType.Map_BookTypeDBID_BookTypeDB {
		forBackup = append(forBackup, booktypeDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	sh, err := file.AddSheet("BookType")
	if err != nil {
		log.Fatal("Cannot add XL file", err.Error())
	}
	_ = sh

	row := sh.AddRow()
	row.WriteSlice(&BookType_Fields, -1)
	for _, booktypeDB := range forBackup {

		var booktypeWOP BookTypeWOP
		booktypeDB.CopyBasicFieldsToBookTypeWOP(&booktypeWOP)

		row := sh.AddRow()
		row.WriteStruct(&booktypeWOP, -1)
	}
}

// RestoreXL from the "BookType" sheet all BookTypeDB instances
func (backRepoBookType *BackRepoBookTypeStruct) RestoreXLPhaseOne(file *xlsx.File) {

	// resets the map
	BackRepoBookTypeid_atBckpTime_newID = make(map[uint]uint)

	sh, ok := file.Sheet["BookType"]
	_ = sh
	if !ok {
		log.Fatal(errors.New("sheet not found"))
	}

	// log.Println("Max row is", sh.MaxRow)
	err := sh.ForEachRow(backRepoBookType.rowVisitorBookType)
	if err != nil {
		log.Fatal("Err=", err)
	}
}

func (backRepoBookType *BackRepoBookTypeStruct) rowVisitorBookType(row *xlsx.Row) error {

	log.Printf("row line %d\n", row.GetCoordinate())
	log.Println(row)

	// skip first line
	if row.GetCoordinate() > 0 {
		var booktypeWOP BookTypeWOP
		row.ReadStruct(&booktypeWOP)

		// add the unmarshalled struct to the stage
		booktypeDB := new(BookTypeDB)
		booktypeDB.CopyBasicFieldsFromBookTypeWOP(&booktypeWOP)

		booktypeDB_ID_atBackupTime := booktypeDB.ID
		booktypeDB.ID = 0
		query := backRepoBookType.db.Create(booktypeDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
		backRepoBookType.Map_BookTypeDBID_BookTypeDB[booktypeDB.ID] = booktypeDB
		BackRepoBookTypeid_atBckpTime_newID[booktypeDB_ID_atBackupTime] = booktypeDB.ID
	}
	return nil
}

// RestorePhaseOne read the file "BookTypeDB.json" in dirPath that stores an array
// of BookTypeDB and stores it in the database
// the map BackRepoBookTypeid_atBckpTime_newID is updated accordingly
func (backRepoBookType *BackRepoBookTypeStruct) RestorePhaseOne(dirPath string) {

	// resets the map
	BackRepoBookTypeid_atBckpTime_newID = make(map[uint]uint)

	filename := filepath.Join(dirPath, "BookTypeDB.json")
	jsonFile, err := os.Open(filename)
	// if we os.Open returns an error then handle it
	if err != nil {
		log.Fatal("Cannot restore/open the json BookType file", filename, " ", err.Error())
	}

	// read our opened jsonFile as a byte array.
	byteValue, _ := ioutil.ReadAll(jsonFile)

	var forRestore []*BookTypeDB

	err = json.Unmarshal(byteValue, &forRestore)

	// fill up Map_BookTypeDBID_BookTypeDB
	for _, booktypeDB := range forRestore {

		booktypeDB_ID_atBackupTime := booktypeDB.ID
		booktypeDB.ID = 0
		query := backRepoBookType.db.Create(booktypeDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
		backRepoBookType.Map_BookTypeDBID_BookTypeDB[booktypeDB.ID] = booktypeDB
		BackRepoBookTypeid_atBckpTime_newID[booktypeDB_ID_atBackupTime] = booktypeDB.ID
	}

	if err != nil {
		log.Fatal("Cannot restore/unmarshall json BookType file", err.Error())
	}
}

// RestorePhaseTwo uses all map BackRepo<BookType>id_atBckpTime_newID
// to compute new index
func (backRepoBookType *BackRepoBookTypeStruct) RestorePhaseTwo() {

	for _, booktypeDB := range backRepoBookType.Map_BookTypeDBID_BookTypeDB {

		// next line of code is to avert unused variable compilation error
		_ = booktypeDB

		// insertion point for reindexing pointers encoding
		// update databse with new index encoding
		query := backRepoBookType.db.Model(booktypeDB).Updates(*booktypeDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
	}

}

// BackRepoBookType.ResetReversePointers commits all staged instances of BookType to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoBookType *BackRepoBookTypeStruct) ResetReversePointers(backRepo *BackRepoStruct) (Error error) {

	for idx, booktype := range backRepoBookType.Map_BookTypeDBID_BookTypePtr {
		backRepoBookType.ResetReversePointersInstance(backRepo, idx, booktype)
	}

	return
}

func (backRepoBookType *BackRepoBookTypeStruct) ResetReversePointersInstance(backRepo *BackRepoStruct, idx uint, booktype *models.BookType) (Error error) {

	// fetch matching booktypeDB
	if booktypeDB, ok := backRepoBookType.Map_BookTypeDBID_BookTypeDB[idx]; ok {
		_ = booktypeDB // to avoid unused variable error if there are no reverse to reset

		// insertion point for reverse pointers reset
		// end of insertion point for reverse pointers reset
	}

	return
}

// this field is used during the restauration process.
// it stores the ID at the backup time and is used for renumbering
var BackRepoBookTypeid_atBckpTime_newID map[uint]uint
